# Awesome_VQA [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/waallf/Awesome_VQA)
==主要介绍使用VQA2.0数据集作为评价指标的论文，使用CLEVR数据集的因为指标已经很高，所以不是关注的重点
[主流数据集VQA2.0介绍](https://arxiv.org/pdf/1505.00468.pdf)  
[Clevr数据集](https://arxiv.org/abs/1612.06890)[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/AntolALMBZP15)
## 使用视觉关系/场景图来做
[Relation-aware Graph Attention Network for Visual Question Answering](https://arxiv.org/pdf/1903.12314.pdf)  
[Bibtex](http://xueshu.baidu.com/u/citation&url=http%3A%2F%2Farxiv.org%2Fabs%2F1903.12314&sign=17cc4cb77edb17296ac50e12a117f52a&diversion=null&t=bib)

[Generating Natural Language Explanations for Visual Question Answering Using Scene Graphs and Visual Attention](https://arxiv.org/pdf/1902.05715.pdf)  没有评价指标，但是是在场景图基础上做的VQA  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1902-05715)
## 使用self-attenton/图卷积  
[LEARNING TO COUNT OBJECTS IN NATURAL IMAGES FOR VISUAL QUESTION ANSWERING](https://arxiv.org/pdf/1802.05766.pdf)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1802-05766)

[Learning Conditioned Graph Structures for Interpretable Visual Question Answering](https://arxiv.org/pdf/1806.07243.pdf)  
[Bibtex]()

## 其他  
[Question Guided Modular Routing Networks for Visual Question Answering](https://arxiv.org/pdf/1904.08324.pdf)   
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1806-07243)  

[Answer Them All! Toward Universal Visual Question Answering Models](https://arxiv.org/pdf/1903.00366.pdf)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1903-00366)

[MUREL: Multimodal Relational Reasoning for Visual Question Answering](https://arxiv.org/pdf/1902.09487.pdf) 所看结果最高，代码公开  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1902-09487)

他的主要参考文献：  
[FiLM: Visual Reasoning with a General Conditioning Layer](https://arxiv.org/abs/1709.07871)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1709-07871)  

[Probabilistic Neural-symbolic Models for Interpretable Visual Question Answering](https://arxiv.org/pdf/1902.07864.pdf)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1902-07864)

[BLOCK: Bilinear Superdiagonal Fusion for Visual Question Answering and Visual Relationship Detection](https://arxiv.org/pdf/1902.00038.pdf)   
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1902-00038)  

[Visual Entailment: A Novel Task for Fine-Grained Image Understanding](https://arxiv.org/pdf/1901.06706.pdf) 使用self-attention    
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1901-06706)

[Compositional Attention Networks for Machine Reasoning](https://arxiv.org/abs/1803.03067)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1803-03067)

[Compositional Attention Networks for Machine Reasoning](https://arxiv.org/abs/1803.03067)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1803-03067)  

[Learning to Reason: End-to-End Module Networks for Visual Question Answering](https://arxiv.org/abs/1704.05526)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/HuARDS17)  

[Inferring and Executing Programs for Visual Reasoning](https://arxiv.org/abs/1705.03633)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/JohnsonHMHLZG17)
