# Awesome_VQA [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/waallf/Awesome_VQA)
==主要介绍使用VQA2.0数据集作为评价指标的论文，使用CLEVR数据集的因为指标已经很高，所以不是关注的重点  
[主流数据集VQA2.0介绍](https://arxiv.org/pdf/1505.00468.pdf)  
[Clevr数据集](https://arxiv.org/abs/1612.06890)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/AntolALMBZP15)  

许多网络的基础  
[ottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](https://arxiv.org/abs/1707.07998)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/AndersonHBTJGZ17)

## 使用视觉关系/场景图来做
[Relation-aware Graph Attention Network for Visual Question Answering](https://arxiv.org/pdf/1903.12314.pdf)   所看结果最高，代码公开，还是图神经网络结果好 emmm..  
[Bibtex](http://xueshu.baidu.com/u/citation&url=http%3A%2F%2Farxiv.org%2Fabs%2F1903.12314&sign=17cc4cb77edb17296ac50e12a117f52a&diversion=null&t=bib)

[Generating Natural Language Explanations for Visual Question Answering Using Scene Graphs and Visual Attention](https://arxiv.org/pdf/1902.05715.pdf)  没有评价指标，但是是在场景图基础上做的VQA  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1902-05715)
## 使用self-attenton/图卷积  
[LEARNING TO COUNT OBJECTS IN NATURAL IMAGES FOR VISUAL QUESTION ANSWERING](https://arxiv.org/pdf/1802.05766.pdf)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1802-05766)

[Learning Conditioned Graph Structures for Interpretable Visual Question Answering](https://arxiv.org/pdf/1806.07243.pdf)  
[Bibtex]()

[Multi-modal Learning with Prior Visual Relation Reasoning](https://arxiv.org/pdf/1812.09681.pdf)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1812-09681)  

[详解](./detail/Multi-modal Learning with Prior Visual Relation Reasoning.md)  

[Bilinear Attention Networks](https://arxiv.org/pdf/1805.07932.pdf)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1805-07932)  
## 用一个语句处理方法，提取出句子中的关键字，然后进行预测  
[Deep Compositional Question Answering with Neural Module Networks](https://arxiv.org/pdf/1511.02799.pdf) 这个方向的鼻祖，利用问题产生不同的网络，还没找见代码  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/AndreasRDK15）

[Learning to Reason: End-to-End Module Networksfor Visual Question Answering](https://arxiv.org/pdf/1704.05526.pdf)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/HuARDS17）

[Inferring and Executing Programs for Visual Reasoning](https://arxiv.org/abs/1705.03633)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/JohnsonHMHLZG17)  

[FiLM: Visual Reasoning with a General Conditioning Layer](https://arxiv.org/abs/1709.07871)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1709-07871) 

## 其他  
[Question Guided Modular Routing Networks for Visual Question Answering](https://arxiv.org/pdf/1904.08324.pdf)   
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1806-07243)  

[Answer Them All! Toward Universal Visual Question Answering Models](https://arxiv.org/pdf/1903.00366.pdf)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1903-00366)

[MUREL: Multimodal Relational Reasoning for Visual Question Answering](https://arxiv.org/pdf/1902.09487.pdf)   
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1902-09487)
 
[Probabilistic Neural-symbolic Models for Interpretable Visual Question Answering](https://arxiv.org/pdf/1902.07864.pdf)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1902-07864)

[BLOCK: Bilinear Superdiagonal Fusion for Visual Question Answering and Visual Relationship Detection](https://arxiv.org/pdf/1902.00038.pdf)   
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1902-00038)  

[Visual Entailment: A Novel Task for Fine-Grained Image Understanding](https://arxiv.org/pdf/1901.06706.pdf) 使用self-attention    
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1901-06706)

[Compositional Attention Networks for Machine Reasoning](https://arxiv.org/abs/1803.03067)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1803-03067)

[Learning to Reason: End-to-End Module Networks for Visual Question Answering](https://arxiv.org/abs/1704.05526)  
[Bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/HuARDS17)  

